{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jv1ZzawXrXMb"
   },
   "source": [
    "# ** Sentiment Analysis Using Fully Connected Feed Forward Neural Network **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgXq-hEErFOH"
   },
   "source": [
    "## **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "39w4toPYrPsX"
   },
   "outputs": [],
   "source": [
    "# Import libraries Pandas and Numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2kAaaGVwrwuA"
   },
   "outputs": [],
   "source": [
    "# Read the training data\n",
    "fname = 'facebook_comments.csv'\n",
    "df_train = pd.read_csv(fname, header = None, names = ['text','sentiment'],encoding = 'iso-8859-1',lineterminator = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "KRJPpA_bsHzT",
    "outputId": "e136a13d-4555-4124-e795-b931c5ac0026"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heres a single  to add  to Kindle. Just read t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you tire of Non-Fiction.. Check out http://...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ghost of Round Island is supposedly nonfiction.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why is Barnes and Nobles version of the Kindle...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Maria:  Do you mean the Nook?  Be careful  bo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Heres a single  to add  to Kindle. Just read t...    neutral\n",
       "1  If you tire of Non-Fiction.. Check out http://...    neutral\n",
       "2   Ghost of Round Island is supposedly nonfiction.     neutral\n",
       "3  Why is Barnes and Nobles version of the Kindle...   negative\n",
       "4  @Maria:  Do you mean the Nook?  Be careful  bo...   positive"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 5 records in the dataset\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "B_n7x9FMsREs",
    "outputId": "59968859-a5f3-4e4b-e6b6-80ec7cedba88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heres a single  to add  to Kindle. Just read t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you tire of Non-Fiction.. Check out http://...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ghost of Round Island is supposedly nonfiction.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why is Barnes and Nobles version of the Kindle...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Maria:  Do you mean the Nook?  Be careful  bo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  labels\n",
       "0  Heres a single  to add  to Kindle. Just read t...    neutral       1\n",
       "1  If you tire of Non-Fiction.. Check out http://...    neutral       1\n",
       "2   Ghost of Round Island is supposedly nonfiction.     neutral       1\n",
       "3  Why is Barnes and Nobles version of the Kindle...   negative       0\n",
       "4  @Maria:  Do you mean the Nook?  Be careful  bo...   positive       2"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get texts and labels \n",
    "sent = {'positive':2,'neutral':1,'negative':0}\n",
    "df_train['labels'] = df_train['sentiment'].str.strip().map(sent)\n",
    "training_texts = df_train.text.values\n",
    "labels = df_train.labels.values\n",
    "print(type(training_texts), type(labels))\n",
    "# Show the first 5 records\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rfDfrlprW-5"
   },
   "source": [
    "## **Preprocess Data** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "W0-DHdyzvCfs",
    "outputId": "c33027cd-d44a-4d4c-bf60-6d53560f1964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 500) , (1999,)\n",
      "[1 1 1 0 2 2 2 0 2 0]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.28915636 0.         0.         0.\n",
      " 0.         0.         0.2971592  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Tokensize and create a document-feature matrix X and label vector Y\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_features=500,ngram_range = (1,1))\n",
    "instances = vectorizer.fit_transform(training_texts)\n",
    "X = instances.toarray()\n",
    "Y = labels\n",
    "\n",
    "# Print out the shape of X and Y \n",
    "print(X.shape,',',Y.shape)\n",
    "print(Y[:10])\n",
    "print(X[0,:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wul5FO3hrwrJ"
   },
   "source": [
    "## **Traditional Machine Learning Models : Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "SB19hFMKr8yH",
    "outputId": "b9a7e6aa-118f-48b0-fc02-59eb3221bb91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - mean: 64.1332% (std: +/- 2.0919%)\n"
     ]
    }
   ],
   "source": [
    "# Using 10-fold cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 2020)\n",
    "rf_model = RandomForestClassifier(criterion = 'entropy', max_depth = 2, random_state = 2020)\n",
    "rf_cvscores = []\n",
    "\n",
    "# Getting the accuracy \n",
    "for train_idx,value_idx in kfold.split(X):\n",
    "  rf_model.fit(X[train_idx],Y[train_idx])\n",
    "  accuracy = rf_model.score(X[value_idx],Y[value_idx])\n",
    "  rf_cvscores.append(accuracy)\n",
    "\n",
    "print(\"Random Forest - mean: %.4f%% (std: +/- %.4f%%)\" % (np.mean(rf_cvscores)*100, np.std(rf_cvscores)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQK5DfxHxBC-"
   },
   "source": [
    "## **Fully Connected Feed Forward Neural Network** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0JqxpSkSw9Bn"
   },
   "outputs": [],
   "source": [
    "# Loading the packages\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "id": "cGSmIY9XCnkD"
   },
   "outputs": [],
   "source": [
    "# Defining the hyperparameters\n",
    "\n",
    "epochs = 20\n",
    "lr = 1e-2\n",
    "in_dim = X.shape[1]\n",
    "out_dim = 3\n",
    "drate = 0.55\n",
    "batch_size = 12\n",
    "\n",
    "# Creating Tensors\n",
    "\n",
    "X_tensor = torch.from_numpy(X)\n",
    "Y_tensor = torch.from_numpy(Y)\n",
    "\n",
    "dataset = TensorDataset(X_tensor,Y_tensor)\n",
    "train_size = int(0.8*len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset,[train_size,val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle = True, batch_size = batch_size)\n",
    "val_loader = DataLoader(val_dataset, shuffle = True, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "id": "PCKJU9E3DXd6"
   },
   "outputs": [],
   "source": [
    "# Creating the network\n",
    "\n",
    "class SentimentNetwork(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim, dropout_rate):\n",
    "    super(SentimentNetwork,self).__init__()\n",
    "    self.fc1 = nn.Linear(in_dim, 1000)\n",
    "    self.fc2 = nn.Linear(1000, 1000)\n",
    "    self.fc3 = nn.Linear(1000, out_dim)\n",
    "    self.do1 = nn.Dropout(dropout_rate)\n",
    "  \n",
    "  def forward(self,x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.do1(x)\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "id": "HaIrWEhdKamL"
   },
   "outputs": [],
   "source": [
    "# Training the network\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "  epoch_loss, epoch_acc = 0.0, 0.0;\n",
    "\n",
    "  model.train()\n",
    "\n",
    "# Training the model to get accuracy and loss for a batch\n",
    "  for batch_x, batch_y in train_loader:\n",
    "    batch_x,batch_y = Variable(batch_x), Variable(batch_y)\n",
    "    optimizer.zero_grad()\n",
    "    network_output = model(batch_x.float())\n",
    "    loss = criterion(network_output,batch_y)\n",
    "    pred = network_output.max(1)[1]\n",
    "    correct = pred.eq(batch_y).sum()\n",
    "    acc = correct.float()/len(pred)*100\n",
    "# Backpropagating the network \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Total loss and accuracy for the batch \n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc\n",
    "  \n",
    "  num_of_batches = train_size/batch_size\n",
    "  avg_epoch_acc = epoch_acc/num_of_batches\n",
    "  avg_epoch_loss = epoch_loss/num_of_batches\n",
    "\n",
    "# Average epoch loss and accuracy \n",
    "  return avg_epoch_loss, avg_epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "id": "iA0ejPT8WIsW"
   },
   "outputs": [],
   "source": [
    "# Evaluating the Network\n",
    "\n",
    "def evaluate(model, val_loader, criterion):\n",
    "  epoch_loss, epoch_acc = 0.0, 0.0;\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "# Evaluating the model to get accuracy and loss for a batch\n",
    "    for batch_x, batch_y in val_loader:\n",
    "      batch_x,batch_y = Variable(batch_x), Variable(batch_y)\n",
    "      network_output = model(batch_x.float())\n",
    "      loss = criterion(network_output,batch_y)\n",
    "      pred = network_output.max(1)[1]\n",
    "      correct = pred.eq(batch_y).sum()\n",
    "      acc = correct.float()/len(pred)*100\n",
    "\n",
    "  # Total loss and accuracy for the batch \n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc\n",
    "  \n",
    "  num_of_batches = val_size/batch_size\n",
    "  avg_epoch_acc = epoch_acc/num_of_batches\n",
    "  avg_epoch_loss = epoch_loss/num_of_batches\n",
    "\n",
    "# Average epoch loss and accuracy \n",
    "  return avg_epoch_loss, avg_epoch_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "id": "x9IRz5EJm2WV"
   },
   "outputs": [],
   "source": [
    "# Defining Gradient Descent, Learning rate and the Loss Criteria \n",
    "\n",
    "network = SentimentNetwork(in_dim,out_dim,drate)\n",
    "optimizer = torch.optim.SGD(network.parameters(),lr = lr, momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XDedxM0so7eV",
    "outputId": "2b14cb58-cd0e-4c25-a0b1-d1f59bf63a5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.8732 | Train Acc: 64.4778\n",
      "\t Val. Loss: 0.8585 |  Val. Acc: 65.0000\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.8289 | Train Acc: 64.8530\n",
      "\t Val. Loss: 0.8340 |  Val. Acc: 64.0000\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.7863 | Train Acc: 64.4778\n",
      "\t Val. Loss: 0.7496 |  Val. Acc: 65.2500\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.6860 | Train Acc: 68.5428\n",
      "\t Val. Loss: 0.6327 |  Val. Acc: 81.5000\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.5765 | Train Acc: 78.5491\n",
      "\t Val. Loss: 0.5564 |  Val. Acc: 80.0000\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.5176 | Train Acc: 80.9256\n",
      "\t Val. Loss: 0.5058 |  Val. Acc: 82.0000\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.4752 | Train Acc: 82.7392\n",
      "\t Val. Loss: 0.4812 |  Val. Acc: 82.5000\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.4474 | Train Acc: 84.2402\n",
      "\t Val. Loss: 0.4349 |  Val. Acc: 85.7500\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.4148 | Train Acc: 84.9906\n",
      "\t Val. Loss: 0.4217 |  Val. Acc: 87.2500\n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.4031 | Train Acc: 85.8662\n",
      "\t Val. Loss: 0.4647 |  Val. Acc: 82.7500\n",
      "Epoch: 11\n",
      "\tTrain Loss: 0.3655 | Train Acc: 86.9919\n",
      "\t Val. Loss: 0.4209 |  Val. Acc: 85.7500\n",
      "Epoch: 12\n",
      "\tTrain Loss: 0.3523 | Train Acc: 87.2420\n",
      "\t Val. Loss: 0.3677 |  Val. Acc: 89.0000\n",
      "Epoch: 13\n",
      "\tTrain Loss: 0.3567 | Train Acc: 87.2420\n",
      "\t Val. Loss: 0.3814 |  Val. Acc: 89.0000\n",
      "Epoch: 14\n",
      "\tTrain Loss: 0.3078 | Train Acc: 89.1182\n",
      "\t Val. Loss: 0.3561 |  Val. Acc: 90.2500\n",
      "Epoch: 15\n",
      "\tTrain Loss: 0.2943 | Train Acc: 88.9306\n",
      "\t Val. Loss: 0.3364 |  Val. Acc: 89.5000\n",
      "Epoch: 16\n",
      "\tTrain Loss: 0.2796 | Train Acc: 89.5560\n",
      "\t Val. Loss: 0.3399 |  Val. Acc: 89.7500\n",
      "Epoch: 17\n",
      "\tTrain Loss: 0.2524 | Train Acc: 90.4315\n",
      "\t Val. Loss: 0.3281 |  Val. Acc: 90.7500\n",
      "Epoch: 18\n",
      "\tTrain Loss: 0.2364 | Train Acc: 92.2451\n",
      "\t Val. Loss: 0.3589 |  Val. Acc: 90.2500\n",
      "Epoch: 19\n",
      "\tTrain Loss: 0.2167 | Train Acc: 92.9331\n",
      "\t Val. Loss: 0.2790 |  Val. Acc: 93.2500\n",
      "Epoch: 20\n",
      "\tTrain Loss: 0.1942 | Train Acc: 94.5591\n",
      "\t Val. Loss: 0.3253 |  Val. Acc: 92.0000\n"
     ]
    }
   ],
   "source": [
    "# Run the training and evaluation process\n",
    "for epoch in range(epochs):\n",
    "  train_loss, train_acc = train(network, train_loader, optimizer, criterion)\n",
    "  valid_loss, valid_acc = evaluate(network, val_loader, criterion)\n",
    "    \n",
    "  print(f'Epoch: {epoch+1:02}')\n",
    "  print(f'\\tTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n",
    "  print(f'\\t Val. Loss: {valid_loss:.4f} |  Val. Acc: {valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHgWlGEfq9df"
   },
   "source": [
    "# Results\n",
    "##### The training accuracy is 94% and the validation accuracy is 92%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "id": "TTBPEdDGVZLo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
