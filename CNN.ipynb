{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sakshi_Sharma.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-TDyMBznyDQ"
      },
      "source": [
        "# Lab 2 - Digit Recognition Using CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_fT6pQ7ar4V"
      },
      "source": [
        "# Loading necessary packages needed for building a CNN network \n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "import torch.optim as optim\n",
        "import os\n",
        "import glob\n",
        "import numpy as np  \n",
        "from skimage import io \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import transform\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import transforms, utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRgDgHaQsMtn",
        "outputId": "945f4b8a-4487-4342-afef-2600b455d76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Loading MNIST Digit Recognition dataset from google drive \n",
        "from google.colab import files,drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QciB5M29teY1",
        "outputId": "a1109511-1900-4f1a-dae0-17aa9b0a350c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# CPU/GPU device assignment \n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Defining network architecture \n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 30, 3)\n",
        "    self.fc1 = nn.Linear(30*5*5, 100)\n",
        "    self.fc2 = nn.Linear(100, 75)\n",
        "    self.fc3 = nn.Linear(75, 10)\n",
        "\n",
        "  # Defining forward method for activation functions \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.log_softmax(self.fc3(x))\n",
        "    return x\n",
        "\n",
        "  # Defining function to flatten output of CNN for Fully connected Feed Forward Neural Network\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:]\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "\n",
        "    return num_features\n",
        "\n",
        "# Creating the network structure\n",
        "net = Net().to(device)\n",
        "print(net)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 30, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=750, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=75, bias=True)\n",
            "  (fc3): Linear(in_features=75, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIlZhY5uoteF"
      },
      "source": [
        "# Creating a customized dataset\n",
        "class MNISTDataset(Dataset):\n",
        "  # Overriding init function to define extra parameters\n",
        "  def __init__(self, dir, transform=None):\n",
        "    self.dir = dir\n",
        "    self.transform = transform\n",
        "  \n",
        "  # Getting length\n",
        "  def __len__(self):\n",
        "    files = glob.glob(self.dir+'/*.jpg')[:100] \n",
        "    return len(files)\n",
        "\n",
        "  # Getting customized instances \n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    all_files = glob.glob(self.dir+'/*.jpg')[:100]\n",
        "    img_fname = os.path.join(self.dir, all_files[idx])\n",
        "    image = io.imread(img_fname)\n",
        "    digit = int(self.dir.split('/')[-1].strip())\n",
        "    label = np.array(digit)\n",
        "    instance = {'image':image,'label':label}\n",
        "    \n",
        "    if self.transform:\n",
        "      instance = self.transform(instance)\n",
        "\n",
        "    return instance"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8cb8V-nrWo2"
      },
      "source": [
        "# Defining custom rescale transformation \n",
        "class Rescale(object):\n",
        "  def __init__(self, output_size):\n",
        "    assert isinstance(output_size, (int, tuple))\n",
        "    self.output_size = output_size\n",
        "\n",
        "# Rescaling an instance with output size\n",
        "  def __call__(self, sample):\n",
        "    image, label = sample['image'], sample['label']\n",
        "    h, w = image.shape[-2:]\n",
        "    if isinstance(self.output_size, int):\n",
        "      if h > w:\n",
        "        new_h, new_w = self.output_size*h/w, self.output_size\n",
        "      else:\n",
        "        new_h, new_w = self.output_size, self.output_size*w/h\n",
        "    else:\n",
        "      new_h, new_w = self.output_size\n",
        "\n",
        "    new_h, new_w = int(new_h), int(new_w)\n",
        "    new_image = transform.resize(image, (new_h, new_w))\n",
        "\n",
        "    return {'image': new_image, 'label':label}\n",
        "\n",
        "# Coverting images and labels to tensors \n",
        "class ToTensor(object):\n",
        "  def __call__(self, sample):\n",
        "    image, label = sample['image'], sample['label']\n",
        "    image = image.reshape((1,image.shape[0],image.shape[1]))\n",
        "    return {'image':torch.from_numpy(image) ,'label': torch.from_numpy(label)}"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EL3UN7RsUNG",
        "outputId": "57846f7a-4abb-41c2-a886-0d5e2611481b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Defining batch size\n",
        "batch_size = 32\n",
        "list_datasets = []\n",
        "\n",
        "# Getting respective datasets for each digits \n",
        "for i in range(10):\n",
        "  cur_ds = MNISTDataset('/content/drive/My Drive/MNIST/trainingset/' + str(i), transform = transforms.Compose([Rescale(28), ToTensor()]))\n",
        "  list_datasets.append(cur_ds)\n",
        "\n",
        "dataset = torch.utils.data.ConcatDataset(list_datasets)\n",
        "print(len(dataset))\n",
        "\n",
        "# Defining the training set size, validation set size \n",
        "train_size = int(len(dataset)*0.7)\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset,[train_size, val_size])\n",
        "\n",
        "# Loading the training and validation set in train dataloader, val dataloader\n",
        "train_dataloader = DataLoader(train_dataset,batch_size,shuffle=True,num_workers=1)\n",
        "val_dataloader = DataLoader(val_dataset,batch_size,shuffle=True,num_workers=1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV_xR4j4-ftt",
        "outputId": "6fb20512-5846-4ff2-83db-944b3ffa7125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Defining epochs, learning rate and loss function for training\n",
        "epochs = 5\n",
        "lr = 1e-3\n",
        "optimizer = optim.Adam(net.parameters(), lr = lr, weight_decay = 1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "# Training the network \n",
        "  net.train()\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for batch_idx, batch in enumerate(train_dataloader):\n",
        "    inputs, targets = batch[\"image\"].to(device, dtype = torch.float), batch[\"label\"].to(device, dtype = torch.long)\n",
        "\n",
        "# Backpropogating the network \n",
        "    optimizer.zero_grad()\n",
        "    predicted_outputs = net(inputs)\n",
        "    loss = criterion(predicted_outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Getting the training accuracy and loss \n",
        "    running_loss += loss.item()\n",
        "    if (batch_idx + 1) % 10 == 0:\n",
        "      print('epoch %d, batch: %d, training loss: %.3f'%(epoch + 1, batch_idx + 1, running_loss/10))\n",
        "      running_loss = 0.0\n",
        "\n",
        "# Evaluating the network \n",
        "  net.eval()\n",
        "\n",
        "  correct = [0.0]*10\n",
        "  total = [0.0]*10\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(val_dataloader):\n",
        "      images, labels = batch[\"image\"].to(device, dtype = torch.float), batch[\"label\"].to(device, dtype = torch.long)\n",
        "      predicted_outputs = net(images)\n",
        "\n",
        "      _, predicted_labels = torch.max(predicted_outputs, 1)\n",
        "      c = (predicted_labels == labels)\n",
        "\n",
        "      # Counting all correctly predicted labels\n",
        "      for i in range(len(labels)):\n",
        "        label = labels[i]\n",
        "        correct[label] += c[i].item()\n",
        "        total[label] += 1\n",
        "\n",
        "# Getting the validation accuracy and loss \n",
        "  for i in range(10):\n",
        "    print('Validation accuracy for digit %d: %.2f'%(i, 100*correct[i]/total[i])) \n",
        "    "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1, batch: 10, training loss: 2.293\n",
            "epoch 1, batch: 20, training loss: 2.246\n",
            "Validation accuracy for digit 0: 96.77\n",
            "Validation accuracy for digit 1: 90.91\n",
            "Validation accuracy for digit 2: 70.97\n",
            "Validation accuracy for digit 3: 68.75\n",
            "Validation accuracy for digit 4: 63.33\n",
            "Validation accuracy for digit 5: 0.00\n",
            "Validation accuracy for digit 6: 90.48\n",
            "Validation accuracy for digit 7: 62.96\n",
            "Validation accuracy for digit 8: 50.00\n",
            "Validation accuracy for digit 9: 33.33\n",
            "epoch 2, batch: 10, training loss: 2.021\n",
            "epoch 2, batch: 20, training loss: 1.674\n",
            "Validation accuracy for digit 0: 96.77\n",
            "Validation accuracy for digit 1: 90.91\n",
            "Validation accuracy for digit 2: 80.65\n",
            "Validation accuracy for digit 3: 81.25\n",
            "Validation accuracy for digit 4: 96.67\n",
            "Validation accuracy for digit 5: 43.33\n",
            "Validation accuracy for digit 6: 61.90\n",
            "Validation accuracy for digit 7: 85.19\n",
            "Validation accuracy for digit 8: 0.00\n",
            "Validation accuracy for digit 9: 3.70\n",
            "epoch 3, batch: 10, training loss: 1.074\n",
            "epoch 3, batch: 20, training loss: 0.959\n",
            "Validation accuracy for digit 0: 87.10\n",
            "Validation accuracy for digit 1: 90.91\n",
            "Validation accuracy for digit 2: 90.32\n",
            "Validation accuracy for digit 3: 87.50\n",
            "Validation accuracy for digit 4: 50.00\n",
            "Validation accuracy for digit 5: 20.00\n",
            "Validation accuracy for digit 6: 85.71\n",
            "Validation accuracy for digit 7: 77.78\n",
            "Validation accuracy for digit 8: 31.58\n",
            "Validation accuracy for digit 9: 85.19\n",
            "epoch 4, batch: 10, training loss: 0.726\n",
            "epoch 4, batch: 20, training loss: 0.810\n",
            "Validation accuracy for digit 0: 93.55\n",
            "Validation accuracy for digit 1: 93.94\n",
            "Validation accuracy for digit 2: 90.32\n",
            "Validation accuracy for digit 3: 93.75\n",
            "Validation accuracy for digit 4: 36.67\n",
            "Validation accuracy for digit 5: 60.00\n",
            "Validation accuracy for digit 6: 85.71\n",
            "Validation accuracy for digit 7: 81.48\n",
            "Validation accuracy for digit 8: 63.16\n",
            "Validation accuracy for digit 9: 81.48\n",
            "epoch 5, batch: 10, training loss: 0.737\n",
            "epoch 5, batch: 20, training loss: 0.586\n",
            "Validation accuracy for digit 0: 93.55\n",
            "Validation accuracy for digit 1: 96.97\n",
            "Validation accuracy for digit 2: 90.32\n",
            "Validation accuracy for digit 3: 84.38\n",
            "Validation accuracy for digit 4: 86.67\n",
            "Validation accuracy for digit 5: 63.33\n",
            "Validation accuracy for digit 6: 95.24\n",
            "Validation accuracy for digit 7: 88.89\n",
            "Validation accuracy for digit 8: 71.05\n",
            "Validation accuracy for digit 9: 77.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k69aWOw2E-hi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}